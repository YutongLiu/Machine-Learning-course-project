---
title: "Human Activity Prediction"
author: "YutongLIU"
date: "Oct 19 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = F, error = F, warning = F,echo = TRUE)
```

## Project overview
Using wareable devices is now possible to collect a large amount of data about personal activity. In this project, our goal is to use this kind of data to predict the exercise manner, so that we can know how well they do the activity and this can help wareable device users to know their exercice performance more easily.

## Data set information
Refer to the [website](http://groupware.les.inf.puc-rio.br/har), this data set records the exercise performed by 6 male participants aged between 20-28 years old.

Participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in  five different fashions: 

Class|Activity
-----|--------
A|exactly according to the speci cation 
B|throwing the elbows to the front
C|lifting the dumbbell only halfway
D|lowering the dumbbell only halfway
E|throwing the hips to the front

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.

> Download the data set

```{R load packages}
library(caret)
library(randomForest)
library(dplyr)
library(ggplot2)
```

Firstly, we downloaded and read in the data set. After a glance of the data, we found that there were different formats of missing value, so we re-read the data and set the NA string format.
```{R download_data,results=FALSE}
#set the working directory
if(!dir.exists("D:/Coursera/L8W4_assignment/"))
   {dir.create("D:/Coursera/L8W4_assignment/");
    setwd("D:/Coursera/L8W4_assignment")}

#download data set
url_training<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"

#download data set
download.file(url=url_training,destfile = "./pml_training.csv")

#read in the data set
pml_training<-read.csv(file = "./pml_training.csv",header = T,
                na.strings = c(""," ","NA","#DIV/0!"))
```

> Preprocess the data set

After loading the training data set, we take a look at it.

* It contains 160 variables and 19622 observations.
```{r glance of data set,results = 'hide'}
#take a look at the data set
str(pml_training)
```

* There are too many missing values, about 98% are missing value in several variables, so if we impute these missing values, the result won't be satisfied.
```{R count missing data,results="hide"}
#count missing data
count_na<-is.na(pml_training)
summary(count_na)
```

These variables contain too much noisy, so finally we removed these variales.
```{R preprocess1}
count_na<-apply(pml_training,2,function(x) sum(is.na(x)))
pml_training<-pml_training[,which(count_na==0)]
```

Obviously the first eight variables are identifiers of each row, this kind of variable shouldn't be used as predictors, so we delete them before training model.
```{R preprocess2}
pml_clean<-pml_training[,8:length(pml_training)]
```

* As the plot shows, the relationship between the outcome and most variables are non-linear. So we can try some non-linear models.

```{R plot,results = T}
qplot(roll_belt,total_accel_belt,colour=classe,data=pml_clean)
```

> Slicing the data set

We sliced the data set into training set and cross-validation set.
```{R slicing data set}
# slicing the data set into 3 folds
set.seed(12345)
inTrain<-createDataPartition(y=pml_clean$classe,p=0.7,
                             list = FALSE)
train_set<-pml_clean[inTrain,]
crossval_set<-pml_clean[-inTrain,]
```

> Train the model

We train the model using decision tree and also random forest.
```{R train the model}
#decision tree
model_dtree<-train(classe~.,data = train_set,method="rpart")

#random forest
model_rf<-randomForest(classe~.,data=train_set)
```

> Predict the outcome with cross-validation set

We predict the outcome with different models using cross-validation data set.
```{R predict the outcome}
outcome_dtree<-predict(model_dtree,crossval_set)
outcome_rf<-predict(model_rf,crossval_set)
```

> Evaluate the out of sample error

From the confusion matrix, we can conclude that the random forest model can predict the class of activity and identify the common mistake types better. 
```{R evaluation}
#Using confusion matrix to evaluate the out of sample error
conmatrix_dtree<-confusionMatrix(outcome_dtree,crossval_set$classe)
conmatrix_rf<-confusionMatrix(outcome_rf,crossval_set$classe)
```
 
Model        |Accuracy
-------------|--------
decision tree| `r conmatrix_dtree$overall[1]`
random forest| `r conmatrix_rf$overall[1]` 

 
```{R evaluation result}
conmatrix_dtree$overall;
conmatrix_rf$overall
```

> Predict the class of test set

```{R test,results=FALSE}
url_testing<-"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url=url_testing,destfile = "./pml_testing.csv")
pml_testing<-read.csv(file = "./pml_testing.csv",header = T,
                      na.strings = c(""," ","NA","#DIV/0!"))

# data preprocessing (same with the training data set)
count_na<-apply(pml_testing,2,function(x) sum(is.na(x)))
pml_testing<-pml_testing[,which(count_na==0)]
testing_clean<-pml_testing[,8:length(pml_testing)]

outcome_test<-predict(model_rf,testing_clean)
```
